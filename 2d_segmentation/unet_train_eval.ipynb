{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a952c10",
   "metadata": {},
   "source": [
    "# MONAI : Tutorial : 2d_segmentation\n",
    "## UNet training / evaluation\n",
    "\n",
    "参照URL:\n",
    "- https://github.com/Project-MONAI/tutorials/tree/main/2d_segmentation/torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b603c",
   "metadata": {},
   "source": [
    "## 0. 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7808cf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.2.dev2302\n",
      "Numpy version: 1.24.1\n",
      "Pytorch version: 1.12.0+cu113\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 708e1a1cf4a1d5516eaf65b8a0bee8887cdee494\n",
      "MONAI __file__: /home/aska/anaconda3/envs/monai/lib/python3.10/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.11.2\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.64.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.4\n",
      "pandas version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# パッケージのインポート\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch, DataLoader, Dataset\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirstd,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "from monai.utils import set_determinism\n",
    "from monai.config import print_config\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94df33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数シードの設定\n",
    "set_determinism(seed=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "698c9b68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'root_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m temp_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/temp_test_data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(temp_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mroot_dir\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'root_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# データフォルダ\n",
    "temp_dir = os.path.realpath('./data/temp_test_data')\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf7cce",
   "metadata": {},
   "source": [
    "## 1. 学習\n",
    "### 1.1 データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ作成\n",
    "for i in range(40):\n",
    "    im, seg = create_test_image_2d(128, 128, num_seg_classes=1)\n",
    "    Image.fromarray((im * 255).astype('uint8')).save(os.path.join(temp_dir, f'img{i:d}.png'))\n",
    "    Image.fromarray((seg * 255).astype('uint8')).save(os.path.join(temp_dir, f'seg{i:d}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習 / 評価 = 20 / 20\n",
    "images = sorted(glob(os.path.join(temp_dir, 'img*.png')))\n",
    "segs = sorted(glob(os.path.join(temp_dir, 'seg*.png')))\n",
    "train_files = [{'img': img, 'seg': seg} for img, seg in zip(images[:20], segs[:20])]\n",
    "val_files = [{'img': img, 'seg': seg} for img, seg in zip(images[20:], segs[20:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e97c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# オリジナル画像\n",
    "img = Image.open(train_files[0]['img'])\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da13f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベル画像\n",
    "seg = Image.open(train_files[0]['seg'])\n",
    "plt.imshow(seg)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31dffaa",
   "metadata": {},
   "source": [
    "## 1.2 データセット, データローダ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232bbdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=['img', 'seg']),\n",
    "        EnsureChannelFirstd(keys=['img', 'seg']),\n",
    "        ScaleIntensityd(keys=['img', 'seg']),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=['img', 'seg'], label_key='seg', spatial_size=[96, 96], pos=1, neg=1, num_samples=4\n",
    "        ),\n",
    "        RandRotate90d(keys=['img', 'seg'], prob=0.5, spatial_axes=[0, 1]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=['img', 'seg']),\n",
    "        EnsureChannelFirstd(keys=['img', 'seg']),\n",
    "        ScaleIntensityd(keys=['img', 'seg']),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12543790",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954cc718",
   "metadata": {},
   "source": [
    "## 1.3 モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779986eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=True, reduction='mean', get_not_nans=False)\n",
    "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル\n",
    "model = monai.networks.nets.UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefeebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899877a",
   "metadata": {},
   "source": [
    "## 1.4 モデル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071844c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 10\n",
    "val_interval = 2\n",
    "\n",
    "model_dir = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "\n",
    "writer = SummaryWriter()\n",
    "epoch_len = len(train_ds) // train_loader.batch_size\n",
    "\n",
    "# epochループ\n",
    "for epoch in range(max_epochs):\n",
    "    print('-' * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    # mini batchループ\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data['img'].to(device), batch_data['seg'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar('train_loss', loss.item(), epoch_len * epoch + step)\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    # 評価\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data['img'].to(device), val_data['seg'].to(device)\n",
    "                roi_size = (96, 96)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "            \n",
    "            metric = dice_metric.aggregate().item()\n",
    "            dice_metric.reset()\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(model_dir, 'best_metric_model_segmentation2d_dict.pth'))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f} \"\n",
    "                f\"best mean dice: {best_metric:.4f} at epoch {best_metric_epoch}\"\n",
    "            )\n",
    "            writer.add_scalar('val_mean_dice', metric, epoch + 1)\n",
    "            plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag='image')\n",
    "            plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag='label')\n",
    "            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag='output')\n",
    "            \n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5696c88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_monai)",
   "language": "python",
   "name": "conda_monai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
